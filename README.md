# finetuningLLM
Product Price Prediction Using Quantized LLMs and QLoRA Fine-Tuning
•	Fine-tuned Meta Llama 3.1-8B using QLoRA with 4-bit quantization to build a lightweight product price prediction model, reducing memory footprint while maintaining performance.
•	 Designed and implemented a full pipeline for evaluating base and fine-tuned models on real-world product description data using custom RMSLE and error classification metrics.
•	Explored and compared multiple tokenizers (LLaMA, Qwen, Gemma, Phi) to assess their suitability for structured data tasks like price extraction.
•	Visualized model predictions vs. ground truth with color-coded scatter plots, highlighting error distribution and insights into model accuracy and generalization.
